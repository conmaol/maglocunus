# LLM Notes

in-context learning

generative versus discriminative models (ie. x vs classifiers) learning a joint districution

masked token prediction versus nect token prediction

encoder - many inputs (eg. image) to one (smaller, fewer dimensional) output (a class)?

decoder - reverse process

embeddings - transforming vectors into new vectors (semantic similarity eg. car, bus)

attention mechanism


