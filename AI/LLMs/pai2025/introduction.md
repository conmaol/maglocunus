# Designing LLM Applications – Introduction

Contents:
- [Defining LLMs](#defining-llms)
- [A brief history of LLMs](#a-brief-history-of-llms)
- [The impact of LLMs](#the-impact-of-llms)
- [LLM usage in the enterprise](#llm-usage-in-the-enterprise)
- [Prompting](#prompting)
- [Accessing LLMs through an API](#accessing-llms-through-an-api)
- [Strengths and limitations of LLMs](#strengths-and-limitations-of-llms)
- [Building your first chatbot prototype](#building-your-first-chatbot-prototype)
- [From prototype to production](#from-prototype-to-production)

§1. LLMs represent one of the most significant technological advances in recent times – a new epoch in the world of tech.

§2. LLMs are a subclass of <mark>generative AI</mark> models – tools which generate responses (images, videos, music, text) to user **prompts**.

## Defining LLMs

§3. A language model approximates human language, embodying aspects of grammar and semantics, having been trained on a large body of text to predict the next word in a known text sequence.

§4. A language model consists of <mark>parameters</mark>, which are iteratively updated during training such that the model gets better at its predictions.

§5. As well as next-word prediction, an LLM seems to be able to learn other, more complex skills during training, for example aspects of reasoning and problem solving. It is currently unclear, however, whether this next-word prediction paradigm can lead to human-level intelligence.

§6. Modern LLMs are based on <mark>neural networks</mark>, usually the **transformer** architecture

§7. LLMs can be used to model more than just human languages – computer programming code, chess moves (Chess-CGP trained on PGN strings to beat experts), DNA sequences (Geneformer trained on single-cell transcriptomes to make predictions about diseases), airline schedules.

§8. LLM <mark>scaling laws</mark> (Kaplan et al 2020) describe a power law relationship between LLM performance, compute time, training dataset, and model size (number of parameters).

§9. Larger LLMs possess <mark>emergent capabilities</mark> – once the model size crosses a threshold, performance suddenly starts to incrase with size on complex tasks like multi-digit arithmetic, logical reasoning, etc. Future, larger models might be able to do all manner of things!

Back up to: [Top](#)

## A brief history of LLMs

Back up to: [Top](#)

## The impact of LLMs

Back up to: [Top](#)

## LLM usage in the enterprise

Back up to: [Top](#)

## Prompting

Back up to: [Top](#)

## Accessing LLMs through an API

Back up to: [Top](#)

## Strengths and limitations of LLMs

Back up to: [Top](#)

## Building your first chatbot prototype

Back up to: [Top](#)

## From prototype to production

Back up to: [Top](#)

----

Back up to: [Top](index.md) | [LLMs](../index.md) | [Artificial Intelligence](../../index.md)
