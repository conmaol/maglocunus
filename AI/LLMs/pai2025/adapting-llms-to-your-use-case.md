# Adapting LLMs to your use case

Contents:
- [Navigating the LLM landscape](#navigating-the-llm-landscape)
- [How to choose an LLM for your task](#how-to-choose-an-llm-for-your-task)
- [Loading LLMs](#loading-llms)
- [Decoding strategies](#decoding-strategies)
- [Running inference on LLMs](#running-inference-on-llms)
- [Structured outputs](#structured-outputs)
- [Model debugging and interpretability](#model-debugging-and-interpretability)

## Navigating the LLM landscape

### Who are the LLM providers?

Types of LLM provider:
- companies providing proprietary LLMs
  - OpenAI (GPT), Google (Gemini), Anthropic (Claude), Cohere, AI2l etc.
  - API endpoints – LLM-as-a-service
  - often parner with cloud providers to provide fullt-managed services: Amazon Bedrock and SageMaker JumpStart, Google’s Vertex AI, Microsoft’s Azure OPenAI. 
- companies providing open source LLMs
  - companies that make LLM weights public and monetise by providing deployment services (TogetherAI)
  - companies whose primary business depends on AI adoption (Cerebras)
  - commercial research labs – Microsoft, Google, Meta, Salesforce etc.
- self-organising open source collectives and community research organisations
  - Eleuther AI, Big Science
- academia and government
  - Abu Dhabi’s Technology Innovation Institute (Falcon model), Tsinghua University (GLM model)

### Model flavours

### Open source LLMs

Back up to: [Top](#)

## How to choose an LLM for your task

### Open source versus proprietary LLMs

### LLM evaluation

Back up to: [Top](#)

## Loading LLMs

### Hugging Face Accelerate

### Ollama

### LLM inference APIs

Back up to: [Top](#)

## Decoding strategies

### Greedy decoding

### Beam search

### Top-k sampling

### Top-p sampling

Back up to: [Top](#)

## Running inference on LLMs

Back up to: [Top](#)

## Structured outputs

Back up to: [Top](#)

## Model debugging and interpretability

Back up to: [Top](#)

----

Back up to: [Top](index.md) | [LLMs](../index.md) | [Artificial Intelligence](../../index.md)
