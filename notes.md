# Notes

## 2025-09-08

Last week the BBC podcast *Radical with Amol Rajan* published an [interview](https://www.bbc.co.uk/sounds/play/m002ht32) with Dario Amadei. This is also available on [BBC iPlayer](https://www.bbc.co.uk/iplayer/episodes/m002f1d0/radical-with-amol-rajan).

Rough sections:
- 1.30: Is AI over-hyped?
  - AI development since 2015 has vastly exceeded expectations
  - gold medals at Math Olympiad
  - 90% of production code at Anthropic
  - PhD level scientist
  - biomedical discoveries
  - clinical study reports
- 6.00: ‘Machines of Love and Grace’
  - huge opportunities!
  - find cures for diseases with complex origins (cancer, Alzheimers, ageing ie. not just viruses)
  - AI can absorb and connect new information much much faster than humans – much faster medical diagnosis
  - economic development in Subsaharan Africa
  - AI will lead to ‘enormous economic growth’
 
13:20

§1. AI will probably lead to a ‘bloodbath’ of entry-level white-collar jobs, within one to five years. AI can already do much of the work typically done by first-year associates at law, consulting and finance firms – repetitive document review and routine financial analysis; basic administrative tasks like coordination, scheduling and note-taking. CEOs are already investing heavily in AI-tools precisely in order to cut costs in this way. Policymakers in government will need to accept that this is coming and ‘handle it well’. The public will need to be informed. \[[Axios interview](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic)\]

19:50

§2. Recent company-internal stress-testing shows that AI models are becoming ever harder to control. They can write special code to avoid being shut down, help to carry out ransomware attacks, and are close to having the skills needed to design biological and other weapons. AI companies need to do thorough, systematic lab-testing of their models, including extreme scenarios. The results need to be shared with rival companies, and with the public (as with car manufacturing). AI companies need to aggressively monitor how the models are being used, and look out for malicious users trying to ‘jailbreak’ their way around the ‘guardrails’. Policymakers need to pay attention to these dangers, and to work closely with all the AI companies to regulate the technology.

- 25.20: Conscience?
- 26.40: lessons learned on asymmetry of power and wealth?
- 29.30: last remarks

## 2025-08-20

Editorial in yesterday’s Guardian: [The Guardian view on Britain’s AI strategy](https://www.theguardian.com/commentisfree/2025/aug/18/the-guardian-view-on-britains-ai-strategy-the-risk-is-that-it-is-dependency-dressed-up-in-digital-hype)

Namechecks two ‘AI thought leaders’:
- [Cecilia Rikap](https://profiles.ucl.ac.uk/94616-cecilia-rikap) (UCL) – recent appearance on Politics Theory Other podcast – “Britain risks becoming a satellite of the US tech industry – a nation whose public infrastructure serves primarily as a testing ground and data source for American AI models hosted on US-owned cloud computing networks”.
- [Daron Acemoglu](https://economics.mit.edu/people/faculty/daron-acemoglu) (MIT) – “Far from ushering in a golden age of labour augmentation, today’s AI rollout is geared almost entirely toward labour displacement. AI can empower workers – or replace them. Right now, it is doing the latter. Ministerial pledges of productivity gains may just mean fewer jobs – not better services.”
  - [The World Needs a Pro-Human AI Agenda](https://www.project-syndicate.org/onpoint/ai-and-agi-designed-to-replace-workers-worst-of-all-possible-worlds-by-daron-acemoglu-2024-11)
  - [When mistakes involve powerful technologies, you’re going to have trouble](https://www.ft.com/content/67e49261-d046-424e-adf7-7cef5cb00292)
  - [The simple macroeconomics of AI](https://economics.mit.edu/sites/default/files/2024-05/The%20Simple%20Macroeconomics%20of%20AI.pdf) – “challenged Goldman Sachs’ 10-year forecast that AI would lead to global growth of 7% – about $7tn – and estimated instead under $1tn in gains. Much of this would be captured by US big tech.”

Summary: 
- The UK Government should:
  - build a public cloud
  - fund open-source AI models
  - create institutions capable of steering technological development toward social ends.
- The UK Government should not:
  - buy AI and cloud technology from American big tech companies, thus increasing our dependence on the US.


