# Notes

## 2025-09-18

### Lisa Crosbie: Copilot Studio - Lite Experience vs Full Experience Explained

Youtube [link](https://www.youtube.com/watch?v=DEmuqilwdn4)

#### The 'lite' experience

Anyone with a MS365 Copilot licence can create a 'lite agent' from within MS365 Copilot Chat. 
- Lite agents are specialist chat assistants to boost personal productivity.
- They can be shared for use by your team (using a link), but you are the sole owner.
- They cannot be published externally.
- They have access to your MS Graph, and also to the wider internet.
- Lite agents are built using no-code methods:
  - You click 'Create agent' in the Copilot Chat sidebar to launch the agent-creating chat assistant.
  - You prompt something like **"Help me communicate with my customers about our range of Contoso Tea products"**.
  - You answer the questions that this agent-creating assistant asks you to set up your lite agent, eg. specifying knowledge sources, tone, name (eg. **'My Contoso Tea assistant'**), etc.
  - You can use the 'Configure' tab to fine-tune these things, eg. specific Sharepoint document libraries, particular websites, your emails, a specific Teams channel or chat, etc.
  - You can include other data sources (eg. Confluence), but only if your IT Admin has set this up in advance.
 - You don't need a Copilot Studio licence to create your own lite agents.
 - Lite agents can only chat with you. They can't **do** anything, eg. send emails or notifications, schedule meetings, etc.

## 2025-09-17

- Guardian: [‘I have to do it’: Why one of the world’s most brilliant AI scientists left the US for China](https://www.theguardian.com/news/ng-interactive/2025/sep/16/song-chun-zhu-why-one-of-the-worlds-most-brilliant-ai-scientists-left-the-us-for-china) - Song-Chun Zhu

## 2025-09-09

- The Economist: [Faith in God-like large language models is waning](https://www.economist.com/business/2025/09/08/faith-in-god-like-large-language-models-is-waning): That may be good news for AI laggards like Apple.
- 

## 2025-09-08 – Dario Amodei

Last week the BBC podcast *Radical with Amol Rajan* published an [interview](https://www.bbc.co.uk/sounds/play/m002ht32) with Dario Amodei. This is also available on [BBC iPlayer](https://www.bbc.co.uk/iplayer/episodes/m002f1d0/radical-with-amol-rajan).

01:30

§1. AI progress is arguably under-hyped. Since 2015, the development of AI technology has vastly exceeded expectations. LLMs have gone from being barely able to produce a coherent grammatical sentence to winning gold medals at the International Maths Olympiad, or writing 90% of Anthropic’s code. Current LLMs can solve PhD-level science problems, helping to make biomedical discoveries like proposing a new molecular structure for a drug (cf. Alphafold). Anthropic’s LLMs are being used by pharmaceutical companies to speed up the approval of clinical trials, from 10 weeks to less than one week.

\[Using AI to diagnose strokes faster: [BBC](https://www.bbc.co.uk/news/articles/cm21d32p9k8o), [Guardian](https://www.theguardian.com/society/2025/sep/01/stroke-centres-in-england-given-ai-tool-that-will-help-50-of-patients-recover)\]

06:00

§2. AI technology brings huge opportunities, especially in biomedicine. It will help us discover cures for diseases with complex origins and evolutions, like cancer, Alzheimers, and the ageing process. AI can absorb and connect far more information far faster than humans can. AI can also speed up routine medical diagnosis, finding things that whole teams of (overwhelmed) doctors have missed.

§3. AI technology can bring economic development and prosperity to places like sub-Saharan Africa, where specialist expertise is currently lacking. AI is likely to generate ‘enormous economic growth’, taking us back to the era of 5–10% a year. 

\[[Machines of Loving Grace](https://www.darioamodei.com/essay/machines-of-loving-grace), Charlotte Blease: [Why we should embrace AI doctors](https://www.theguardian.com/books/2025/aug/31/the-big-idea-why-we-should-embrace-ai-doctors)\]
 
13:20

§4. AI will probably lead to a ‘bloodbath’ of entry-level white-collar jobs, within one to five years. AI can already do much of the work typically done by first-year associates at law, consulting and finance firms – repetitive document review and routine financial analysis; basic administrative tasks like coordination, scheduling and note-taking. CEOs are already investing heavily in AI-tools precisely in order to cut costs in this way. Policymakers in government will need to accept that this is coming and ‘handle it well’. The public will need to be kept informed. 

\[[Axios interview](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic)\]

19:50

§5. Recent company-internal stress-testing shows that AI models are becoming ever harder to control. They can write special code to avoid being shut down, help to carry out ransomware attacks, and are close to having the skills needed to design biological and other weapons. AI companies need to do thorough, systematic lab-testing of their models, including extreme scenarios. The results need to be shared with rival companies, and with the public (as with car manufacturing). AI companies need to aggressively monitor how the models are being used, and look out for malicious users trying to ‘jailbreak’ their way around the ‘guardrails’. Policymakers need to pay attention to these dangers, and to work closely with all the AI companies to ‘sensibly’ regulate the technology.

26:40

§6. It is ‘baffling’ and ‘disturbing’ and ‘insane’ (given the well-known negative impacts of social media technology) that other AI companies and (‘financially conflicted’) investors are (‘frankly corruptly’) lobbying governments aggressively to deregulate AI technology (eg. a 10-year moratorium on state-level AI regulation). We need ‘sensible, responsible oversight’, that is not too ‘rigid and aggressive’ and that doesn’t prevent us reaping the benefits.

## 2025-08-20

Editorial in yesterday’s Guardian: [The Guardian view on Britain’s AI strategy](https://www.theguardian.com/commentisfree/2025/aug/18/the-guardian-view-on-britains-ai-strategy-the-risk-is-that-it-is-dependency-dressed-up-in-digital-hype)

Namechecks two ‘AI thought leaders’:
- [Cecilia Rikap](https://profiles.ucl.ac.uk/94616-cecilia-rikap) (UCL) – recent appearance on Politics Theory Other podcast – “Britain risks becoming a satellite of the US tech industry – a nation whose public infrastructure serves primarily as a testing ground and data source for American AI models hosted on US-owned cloud computing networks”.
- [Daron Acemoglu](https://economics.mit.edu/people/faculty/daron-acemoglu) (MIT) – “Far from ushering in a golden age of labour augmentation, today’s AI rollout is geared almost entirely toward labour displacement. AI can empower workers – or replace them. Right now, it is doing the latter. Ministerial pledges of productivity gains may just mean fewer jobs – not better services.”
  - [The World Needs a Pro-Human AI Agenda](https://www.project-syndicate.org/onpoint/ai-and-agi-designed-to-replace-workers-worst-of-all-possible-worlds-by-daron-acemoglu-2024-11)
  - [When mistakes involve powerful technologies, you’re going to have trouble](https://www.ft.com/content/67e49261-d046-424e-adf7-7cef5cb00292)
  - [The simple macroeconomics of AI](https://economics.mit.edu/sites/default/files/2024-05/The%20Simple%20Macroeconomics%20of%20AI.pdf) – “challenged Goldman Sachs’ 10-year forecast that AI would lead to global growth of 7% – about $7tn – and estimated instead under $1tn in gains. Much of this would be captured by US big tech.”

Summary: 
- The UK Government should:
  - build a public cloud
  - fund open-source AI models
  - create institutions capable of steering technological development toward social ends.
- The UK Government should not:
  - buy AI and cloud technology from American big tech companies, thus increasing our dependence on the US.


