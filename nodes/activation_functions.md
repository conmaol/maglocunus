# Activation functions

Every artificial neuron has a characteristic activation function, which decides what the neuronâ€™s output should be based on the sum of its weighted inputs.

Note that:
- The input to an activation function is a real number (positive or negative).
- The output of an activation function is also a real number (positive or negative).

Examples of commonly used activation functions are:
- the [standard logistic function](standard_logistic_function.md) (sigmoid)
- the [rectified linear unit function](rectified_linear_unit.md) (ReLU) 

See also:
- Wikipedia page on [activation functions](https://en.wikipedia.org/wiki/Activation_function)

----

Back to: [Index](index.md)
